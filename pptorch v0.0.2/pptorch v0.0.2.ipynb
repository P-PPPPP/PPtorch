{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各类函数\n",
    "class function:\n",
    "    def __init__(self):\n",
    "        pass;\n",
    "    def activate(self,f,x):\n",
    "        if f == 'relu':\n",
    "            return self.relu(x);\n",
    "        if f == 'softmax':\n",
    "            return self.softmax(x);\n",
    "        if f == 'sigmoid':\n",
    "            return self.sigmoid(x);\n",
    "        if f == 'x':\n",
    "            return x;\n",
    "    def loss(self,f,y,label):\n",
    "        if f == 'MSE':\n",
    "            return 1/y.shape[0] * 1/2* np.sum((y - label)**2);\n",
    "        if f == 'Cross_Entropy':\n",
    "            res = - np.sum(label*np.log(y),axis=1);\n",
    "            return 1/y.shape[0] * np.sum(res);\n",
    "        if f == 'Real_Cross_Entropy':\n",
    "            res = - np.sum(label*np.log(y)+(1-label)*np.log(1-y),axis=1);\n",
    "            return 1/y.shape[0] * np.sum(res);\n",
    "    def gra_func(self,f,x,y=None):\n",
    "        if f == 'relu':\n",
    "            return self.gra_relu(x);\n",
    "        if f =='softmax':\n",
    "            return self.gra_softmax(x);\n",
    "        if f == 'sigmoid':\n",
    "            return self.gra_sigmoid(x);\n",
    "        if f == 'x':\n",
    "            return 1;\n",
    "    def gra_loss(self,f,y,label):\n",
    "        if f == 'MSE':\n",
    "            return (y-label);\n",
    "        if f == 'Cross_Entropy':\n",
    "            return -label/y;\n",
    "        if f == 'Real_Cross_Entropy':\n",
    "            return -(label/y-(1-label)/(1-y));\n",
    "    def relu(self,x):\n",
    "        res = np.abs(x);\n",
    "        res = (res + x)/2;\n",
    "        return res;\n",
    "    def softmax(self,x):\n",
    "        x = x.T - np.max(x,axis=1).T;\n",
    "        x = x.T # 减去最大，防止溢出 \n",
    "        res = np.exp(x).T/np.sum(np.exp(x),axis=1).T\n",
    "        return res.T;\n",
    "    def sigmoid(self,x):\n",
    "        r1 = 1/(1+np.exp(-self.relu(x)));\n",
    "        r2 = np.exp(-self.relu(-x))/(1+np.exp(-self.relu(-x)));\n",
    "        return (r1+r2-1/2);\n",
    "    def gra_relu(self,x):\n",
    "        res = np.abs(x);\n",
    "        res = np.sign(res + x);\n",
    "        return res;\n",
    "    def gra_softmax(self,x):\n",
    "        x = x.T - np.max(x,axis=1).T;\n",
    "        x = x.T\n",
    "        out = np.exp(x).T/np.sum(np.exp(x),axis=1).T\n",
    "        out = out.T\n",
    "        return (out - out**2);\n",
    "    def gra_sigmoid(self,x):\n",
    "        r1 = np.exp(-self.relu(x))/(1+np.exp(-self.relu(x)))**2;\n",
    "        r2 = np.exp(-self.relu(-x))/(1+np.exp(-self.relu(-x)))**2;\n",
    "        return (r1+r2-1/4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义层\n",
    "class class_layers:    \n",
    "    def __init__(self):\n",
    "        pass;\n",
    "    def flatten(self,input_shape = None):\n",
    "        # 该方法将任意输入形状数据展平;\n",
    "        return {'type':'flatten','input_shape':input_shape};\n",
    "    def dense(self,num_nets = None,activation = 'relu',learning_rate=0.01): \n",
    "        # 一层全连接神经网络\n",
    "        return {'type':'dense','num_nets':num_nets,'activation_func':activation,'learning_rate':learning_rate};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_process:\n",
    "    def __init__(self):\n",
    "        pass;\n",
    "    # 随机打乱输入数据，将数据划分为训练/测试集\n",
    "    def random_division(self,x,y=None,test_rate = 0):\n",
    "        x = np.array(x);\n",
    "        # 数据总长度\n",
    "        n = np.shape(x)[0];\n",
    "        # 生成下表序列并随即打乱\n",
    "        sequence = np.array(range(n));\n",
    "        np.random.shuffle(sequence);\n",
    "        # 测试集长度\n",
    "        n_test = int(np.ceil(n * test_rate));\n",
    "        # 测试集序列与训练集序列\n",
    "        se_test = sequence[:n_test];\n",
    "        se_train = sequence[n_test:];\n",
    "        # 训练集\n",
    "        train_data = x[se_train];\n",
    "        # 测试集\n",
    "        test_data = x[se_test];\n",
    "        # 有监督学习的情况\n",
    "        if not type(y) == type(None):\n",
    "            y = np.array(y);\n",
    "            train_label = y[se_train];\n",
    "            test_label = y[se_test];\n",
    "            if not test_rate == 0:\n",
    "                return (train_data,train_label,test_data,test_label);\n",
    "            else:\n",
    "                return (train_data,train_label);\n",
    "        # 无监督情况\n",
    "        if not test_rate == 0:\n",
    "            return (train_data,test_data);\n",
    "        else:\n",
    "            return (train_data);\n",
    "    # 归一化\n",
    "    def normalization(self,x_train,x_test=None,norm_type= 'max_abs'):\n",
    "        # 最大绝对值放缩\n",
    "        if norm_type == 'max_abs':\n",
    "            max_abs = np.max(np.abs(x_train),axis=0)\n",
    "            x_train = x_train/max_abs;\n",
    "            if not type(x_test) == type(None):\n",
    "                x_test = x_test / max_abs;\n",
    "        # 最大最小值归一化\n",
    "        if norm_type == 'max_min':\n",
    "            max_v = np.max(x_train);\n",
    "            min_v = np.min(x_train);\n",
    "            x_train = (max_v - x_train) / (max_v - min_v);\n",
    "            if not type(x_test) == type(None):\n",
    "                x_test = (max_v - x_test) / (max_v - min_v);\n",
    "        # 标准化\n",
    "        if norm_type == 'norm':\n",
    "            mean_v = np.mean(x_train,axis=0);\n",
    "            std_v = np.std(x_train,axis=0);\n",
    "            x_train = (max_v - mean_v) / std_v;\n",
    "            if not type(x_test) == type(None):\n",
    "                x_test = (max_v - mean_v) / std_v;\n",
    "        # 函数返回\n",
    "        if not type(x_test) == type(None):\n",
    "            return (x_train,x_test);\n",
    "        return x_train;\n",
    "    # 将数字标签转化为one hot标签\n",
    "    def onehot_label(self,label):\n",
    "        max_num = np.max(label);\n",
    "        res = [];\n",
    "        for k in range(len(label)):\n",
    "            resk = np.zeros((max_num+1,));\n",
    "            resk[label[k]] = 1;\n",
    "            res.append(resk);\n",
    "        return np.array(res);\n",
    "    # 在定义batch时，将原数据分段\n",
    "    def batch_slice(self,batch,n):\n",
    "        train_list = [];\n",
    "        if batch <= 0 or batch >n:\n",
    "            batch = n;\n",
    "            train_list.append([0,n]);\n",
    "        else:\n",
    "            m = n//batch;\n",
    "            for k in range(m):\n",
    "                train_list.append([k*batch,(k+1)*batch]);\n",
    "            if not n%batch == 0:\n",
    "                train_list.append([(k+1)*batch,n]);\n",
    "        return train_list;\n",
    "    # 返回多分类的onehot表示\n",
    "    def arg_max(y):\n",
    "        tar = np.argmax(y,axis=1);\n",
    "        res = np.zeros_like(y);\n",
    "        for i in range(y.shape[0]):\n",
    "            res[i,tar[i]] = 1;\n",
    "        return res;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fit_info:\n",
    "    def __init__(self):\n",
    "        pass;      \n",
    "    def state_display(self,state,timer,loss=-1,epoch=1,epoches=1,batch=-1,all=-1,metrics=None,metrics_value=None):\n",
    "        # title\n",
    "        if state == 1:\n",
    "            print('Epoch {}/{}'.format(epoch+1,epoches));\n",
    "            self.n_str = 0;\n",
    "        # loading bar\n",
    "        if state == 2:\n",
    "            self.loading_bar(timer,timer/all,all,loss,metrics=metrics,metrics_value=metrics_value);\n",
    "    # 进度条\n",
    "    def loading_bar(self,timer,process,all,loss,metrics=None,metrics_value=None):\n",
    "        n = int(process*30) + 1;\n",
    "        m = 30-n;\n",
    "        s = '{}/{} '.format(timer,all);\n",
    "        s += '[' + '='*n + '-'*m + ']';\n",
    "        s += '\\tloss: {:.2f}'.format(loss);\n",
    "        if not type(metrics) == type(None):\n",
    "            s += ' {}: {:.2f}'.format(metrics,metrics_value);\n",
    "        n = len(s);\n",
    "        s += ' '*(self.n_str - n);\n",
    "        print('\\r',end='')\n",
    "        print(s,end='');\n",
    "        if n > self.n_str:\n",
    "            self.n_str = n;\n",
    "    # 分类网络的评价指标\n",
    "    def evaluate(self,y,label,metrics='Accuracy'):\n",
    "        confusion_matrix = np.dot(label.T,y);\n",
    "        cm = confusion_matrix;\n",
    "        # 对角线元素+1 防止溢出\n",
    "        cm = cm + np.eye(cm.shape[0]);\n",
    "        N = y.shape[0] + cm.shape[0];\n",
    "        n = y.shape[1];\n",
    "        T = np.diagonal(cm);\n",
    "        A = np.trace(cm)/N;\n",
    "        Pk = T/np.sum(cm,axis=0);\n",
    "        P = np.sum(Pk)/n;\n",
    "        Rk = T/np.sum(cm,axis=1).T;\n",
    "        R = np.sum(Rk)/n;\n",
    "        F1 = 2*P*R/(P+R);\n",
    "        if metrics == 'Accuracy':\n",
    "            return A;\n",
    "        if metrics == 'Precision':\n",
    "            return P;\n",
    "        if metrics == 'Recall':\n",
    "            return R;\n",
    "        if metrics == 'F1':\n",
    "            return F1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    # 类初始化\n",
    "    def __init__(self):\n",
    "        self.model_state = {'compile_model':False,'loading_data':False};\n",
    "        self.structure = {};\n",
    "        self.info = {};\n",
    "        self.num_layers = 0;\n",
    "        self.parameter = {};\n",
    "        self.layers = class_layers();\n",
    "        self.res_layer ={};\n",
    "        self.median_value = {};\n",
    "        self.error = None;\n",
    "        self.nets = [];\n",
    "        self.in_shape = [];\n",
    "        self.out_shape = [];\n",
    "        self.func = function();\n",
    "        self.data_proc = data_process();\n",
    "        self.fit_state = fit_info();\n",
    "\n",
    "    # 向模型加载数据\n",
    "    def load_data(self,\n",
    "    train_data=None,\n",
    "    train_label=None,\n",
    "    validation_data=None,\n",
    "    validation_label=None,\n",
    "    random_train_set=True,\n",
    "    auto_test_set=False,\n",
    "    test_proportion=0.1,\n",
    "    data_normalization=False,\n",
    "    normalization_type='max_abs'\n",
    "    ):\n",
    "        # 自动划分测试集合\n",
    "        if auto_test_set == True:\n",
    "            if not type(train_label) == type(None):\n",
    "                # 有监督情况\n",
    "                (train_data,train_label,validation_data,validation_label) = self.data_proc.random_division(train_data,train_label,test_rate=test_proportion);\n",
    "            else:\n",
    "                # 无监督情况\n",
    "                (train_data,validation_data) = self.data_proc.random_division(train_data,test_rate=test_proportion);\n",
    "        # 训练数据随机化\n",
    "        elif random_train_set == True:\n",
    "            if not type(train_label) == type(None):\n",
    "                # 有监督情况\n",
    "                (train_data,train_label) = self.data_proc.random_division(train_data,train_label,test_rate=0);\n",
    "            else:\n",
    "                # 无监督情况\n",
    "                (train_data) = self.data_proc.random_division(train_data,test_rate=0);\n",
    "        # 数据归一化\n",
    "        if data_normalization == True:\n",
    "            if not type(validation_data) == type(None):\n",
    "                (train_data,validation_data) = self.data_proc.normalization(train_data,validation_data,normalization_type);\n",
    "            else:\n",
    "                train_data = self.data_proc.normalization(train_data,None,normalization_type);\n",
    "        # 记录加载训练集信息\n",
    "        if not type(train_data) == type(None):\n",
    "            self.train_data = train_data;\n",
    "            self.model_state.update({'loading_train_data':True});\n",
    "            self.info.update({'num_train_data':train_data.shape[0]});\n",
    "            self.n_train = train_data.shape[0];\n",
    "        if not type(train_label) == type(None):\n",
    "            self.train_label = train_label;\n",
    "            self.model_state.update({'loading_train_label':True});\n",
    "            self.d_train = train_data.shape[1:];\n",
    "        # 记录加载验证集信息\n",
    "        if not type(validation_data) == type(None):\n",
    "            self.validation_data = validation_data;\n",
    "            self.model_state.update({'loading_validation_data':True});\n",
    "            self.info.update({'num_validation_data':validation_data.shape[0]});\n",
    "            self.n_val = validation_data[0];\n",
    "        if not type(validation_label) == type(None):\n",
    "            self.validation_label = validation_label;\n",
    "            self.model_state.update({'loading_validation_label':True});\n",
    "            self.d_val = validation_data[1:];\n",
    "        # 记录数据加载信息\n",
    "        if self.model_state['loading_train_data'] == True and self.model_state['loading_train_label'] == True:\n",
    "            self.model_state['loading_data'] = True;\n",
    "\n",
    "    # 描述新的网络结构\n",
    "    def define(self,BP_structure = None):\n",
    "        if not type(BP_structure) == type(None):\n",
    "            self.layer_type = [];\n",
    "            for layer in BP_structure:\n",
    "                self.structure.update({self.num_layers:layer});\n",
    "                self.layer_type.append(layer['type']);\n",
    "                self.num_layers += 1;\n",
    "    # 向已有结构新添层\n",
    "    def add(self,new_layer):\n",
    "        self.structure.update({self.num_layers:new_layer});\n",
    "        self.num_layers += 1;\n",
    "    # 网络编译初始化参数\n",
    "    def compile_init(self):\n",
    "        self.x = [];\n",
    "        self.y = [];\n",
    "        self.w = [];\n",
    "        self.b =[];\n",
    "        self.nets = [];\n",
    "        self.rate = [];\n",
    "        self.activation_function =[];\n",
    "        self.delta = [];\n",
    "    # 编译网络输入输出的维度信息\n",
    "    def compile_dim_info(self):\n",
    "        n = self.n_train;\n",
    "        d = self.d_train;\n",
    "        out_shape = d;\n",
    "        for k in range(self.num_layers):\n",
    "            layer = self.structure[k];\n",
    "            if layer['type'] == 'flatten':\n",
    "                in_shape = out_shape;\n",
    "                out_shape = 1;\n",
    "                for p in d:\n",
    "                    out_shape *= p;\n",
    "                self.nets.append(np.array([]));\n",
    "                self.in_shape.append(in_shape);\n",
    "                self.out_shape.append(out_shape);\n",
    "                continue;\n",
    "            if layer['type'] == 'dense':\n",
    "                in_shape = out_shape;\n",
    "                out_shape = layer['num_nets'];\n",
    "                self.nets.append(layer['num_nets']);\n",
    "                self.in_shape.append(in_shape);\n",
    "                self.out_shape.append(out_shape);\n",
    "                continue;\n",
    "    # 编译网络所需要的中间量\n",
    "    def compile_param_info(self):\n",
    "        for k in range(self.num_layers):\n",
    "            layer = self.structure[k];\n",
    "            if layer['type'] == 'flatten':\n",
    "                self.x.append(np.array([]));\n",
    "                self.y.append(np.array([]));\n",
    "                self.w.append(np.array([]));\n",
    "                self.b.append(np.array([]));\n",
    "                self.rate.append(np.array([]));\n",
    "                self.activation_function.append(np.array([]));\n",
    "                self.delta.append(np.array([]));\n",
    "                continue;\n",
    "            if layer['type'] == 'dense':\n",
    "                N1 = self.in_shape[k];\n",
    "                N2 = self.out_shape[k];\n",
    "                w = np.random.randn(N1,N2);\n",
    "                b = np.random.randn(1,N2);\n",
    "                self.x.append(np.array([]));\n",
    "                self.y.append(np.array([]));\n",
    "                self.w.append(w);\n",
    "                self.b.append(b);\n",
    "                self.rate.append(layer['learning_rate']);\n",
    "                self.activation_function.append(layer['activation_func']);\n",
    "                self.delta.append(np.array([]));\n",
    "                continue;\n",
    "\n",
    "        if not N2 == len(self.train_label[0]):\n",
    "            raise Exception(\"UNFITTED OUTPUT LAYER\");\n",
    "    # 编译该神经网络\n",
    "    def compile(self,loss_function = 'MSE',optimizer='SGD',metrics = None):\n",
    "        self.loss_function = loss_function;\n",
    "        self.optimizer = optimizer;\n",
    "        self.metrics = metrics;\n",
    "        self.compile_init();\n",
    "        # 维度信息\n",
    "        self.compile_dim_info();\n",
    "        # 参数信息\n",
    "        self.compile_param_info();\n",
    "        self.model_state['compile_model']=True;\n",
    "    # 模型训练\n",
    "    def fit(self,epoches=1,batch = -1):\n",
    "        # 防止未加载数据或未编译网络时训练\n",
    "        if self.model_state['compile_model'] == False or self.model_state['loading_data'] == False:\n",
    "            raise Exception(\"UNINITIALIZED MODEL: (loading data:{}, compile model:{})\".format(\n",
    "                self.model_state['loading_data'],self.model_state['compile_model']));\n",
    "        # BGD优化训练\n",
    "        if self.optimizer == 'BGD':\n",
    "            self.BGD(epoches,batch);\n",
    "    # 前向传播\n",
    "    def forward_propagation(self,x0):\n",
    "        # 输入层\n",
    "        if self.layer_type[0] == 'flatten':\n",
    "            x = x0;\n",
    "            y = [];\n",
    "            for i in range(x.shape[0]):\n",
    "                xk = x[i];\n",
    "                y.append(xk.reshape(-1));\n",
    "        elif self.layer_type[0] == 'dense':\n",
    "            x = np.dot(x0,self.w[0]) + self.b[0];\n",
    "            y = self.func.activate(self.activation_function[0],x);\n",
    "        self.x[0] = x;\n",
    "        self.y[0] = np.array(y);\n",
    "        # 隐藏层\n",
    "        for k in range(1,len(self.nets)):\n",
    "            if self.layer_type[k] == 'flatten':\n",
    "                x = self.y[k-1];\n",
    "                y = [];\n",
    "                for i in range(len(x)):\n",
    "                    xk = x[i];\n",
    "                    y.append(xk.reshape(-1));\n",
    "                self.x[k] = x;\n",
    "                self.y[k] = np.array(y);\n",
    "            elif self.layer_type[k] == 'dense':\n",
    "                x = np.dot(self.y[k-1],self.w[k]) + self.b[k];\n",
    "                y = self.func.activate(self.activation_function[k],x);\n",
    "                self.x[k] = x;\n",
    "                self.y[k] = y;\n",
    "    # 反向传播\n",
    "    def backward_propagation(self,label):\n",
    "        # 输出层情况\n",
    "        k = len(self.nets) - 1;\n",
    "        delta = self.func.gra_loss(self.loss_function,self.y[k],label) * self.func.gra_func(self.activation_function[k],self.x[k]);\n",
    "        db = np.sum(delta,axis=0).reshape(1,-1);\n",
    "        dw = np.dot(self.y[k-1].T,delta);\n",
    "        self.b[k] -= self.rate[k]*db;\n",
    "        self.w[k] -= self.rate[k]*dw;\n",
    "        self.delta[k] = delta;\n",
    "        k -= 1;\n",
    "        # 隐藏层\n",
    "        while(k>0):\n",
    "            if self.layer_type[k] == 'flatten':\n",
    "                delta = self.delta[k+1];\n",
    "                delta = delta.reshape(-1,self.in_shape[k]);\n",
    "                self.delta[k] = delta;\n",
    "            elif self.layer_type[k] == 'dense':\n",
    "                delta = np.dot(self.delta[k+1],self.w[k+1].T) * self.func.gra_func(self.activation_function[k],self.x[k]);\n",
    "                db = np.sum(delta,axis = 0).reshape(1,-1);\n",
    "                dw = np.dot(self.y[k-1].T,delta);\n",
    "                self.b[k] -= self.rate[k]*db;\n",
    "                self.w[k] -= self.rate[k]*dw;\n",
    "                self.delta[k] = delta;\n",
    "            k -= 1;\n",
    "\n",
    "    # BGD优化器\n",
    "    def BGD(self,epoches,batch = -1):\n",
    "        if batch <= 0 or batch > self.n_train:\n",
    "            batch = self.n_train;\n",
    "        trian_list = self.data_proc.batch_slice(batch,self.n_train)\n",
    "        for p in range(epoches):\n",
    "            self.timer = 0;\n",
    "            self.fit_state.state_display(state=1,timer=self.timer,epoch=p,epoches=epoches);\n",
    "            for k in trian_list:\n",
    "                self.timer += 1;\n",
    "                x0 = self.train_data[k[0]:k[1]];\n",
    "                label = self.train_label[k[0]:k[1]];\n",
    "                # 正向传播\n",
    "                self.forward_propagation(x0);\n",
    "                # 计算误差\n",
    "                loss = self.func.loss(self.loss_function,self.y[-1],label);\n",
    "                # 反向传播\n",
    "                self.backward_propagation(label);\n",
    "                # 输出误差\n",
    "                metrics_value = None;\n",
    "                if not type(self.metrics) == type(None):\n",
    "                    metrics_value = self.fit_state.evaluate(self.y[-1],label,self.metrics)\n",
    "                self.fit_state.state_display(state=2,timer=self.timer,loss=loss,all=len(trian_list),metrics = self.metrics,metrics_value = metrics_value);\n",
    "            print('');\n",
    "    # 训练状态信息输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "names_to_label = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2};\n",
    "label_to_names = {value: key for key, value in names_to_label.items()}\n",
    "df = pd.read_csv('iris.data', header=None)\n",
    "xs = df.iloc[:, :4].values\n",
    "ts = np.array([names_to_label[name] for name in df.iloc[:, -1]])\n",
    "ts = ts.reshape(-1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调取模组\n",
    "pp = model();\n",
    "# onehot label\n",
    "ys = pp.data_proc.onehot_label(ts);\n",
    "# 加载数据\n",
    "pp.load_data(\n",
    "    train_data = xs,\n",
    "    train_label = ys,\n",
    "    auto_test_set=True,# 从训练集划分出测试集\n",
    "    test_proportion=0.1,# 划分的测试集的比例\n",
    "    data_normalization=True,# 对数据归一化\n",
    "    normalization_type='max_abs'# 归一化的类型\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "rate = 1e-4;\n",
    "pp.define([\n",
    "    pp.layers.flatten(),\n",
    "    pp.layers.dense(num_nets=32,activation='relu',learning_rate=rate),\n",
    "    pp.layers.dense(num_nets=128,activation='relu',learning_rate=rate),\n",
    "    pp.layers.dense(num_nets=64,activation='sigmoid',learning_rate=rate),\n",
    "    pp.layers.dense(num_nets=3,activation='softmax',learning_rate=rate)\n",
    "])\n",
    "# 编译网络\n",
    "pp.compile(loss_function = 'MSE',optimizer='BGD',metrics='Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 2/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 3/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 4/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 5/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 6/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 7/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 8/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 9/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 10/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 11/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 12/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 13/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 14/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 15/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 16/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 17/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 18/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 19/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.87\n",
      "Epoch 20/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 21/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 22/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 23/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 24/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 25/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 26/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 27/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 28/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 29/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 30/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 31/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 32/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 33/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 34/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 35/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 36/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 37/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 38/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 39/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 40/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 41/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 42/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 43/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 44/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 45/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 46/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 47/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 48/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 49/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 50/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 51/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 52/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 53/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 54/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 55/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 56/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 57/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 58/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 59/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 60/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 61/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 62/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 63/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 64/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 65/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 66/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 67/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 68/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 69/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.88\n",
      "Epoch 70/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 71/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 72/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 73/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 74/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 75/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 76/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 77/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 78/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 79/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 80/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 81/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 82/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 83/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 84/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 85/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 86/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 87/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 88/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 89/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 90/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 91/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 92/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 93/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 94/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 95/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 96/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 97/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 98/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 99/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n",
      "Epoch 100/100\n",
      "1/1 [===============================]\tloss: 0.03 Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "pp.fit(epoches=100,batch=-1);\n",
    "# epoches 总的迭代次数\n",
    "# batch 每次训练的样本数量\n",
    "# batch <= 1 or batch >= 所有样本：训练所有样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54087ba96b7f69cbb53f2c9fca84f0bfbd80e0b1621aa08811937a5cae8ab899"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
